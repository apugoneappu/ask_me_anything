# Visual Question Answering Visualiser (VQA-VIZ)
An easy-to-use app to visualise attentions of various VQA models.

## Demo
![landing page of vqa-viz](https://drive.google.com/uc?export=view&id=1WOoMT_Y4gE9ZojIZ4BxsWa636qE9mfvt)
![landing page of vqa-viz](https://drive.google.com/uc?export=view&id=1SpBwiZS1EPihyJxXixdw8_XZyZkTQQs_)
![landing page of vqa-viz](https://drive.google.com/uc?export=view&id=1_yUgnz8fG_vcw3FV-0E0G9dB1WsNKSxS)
![landing page of vqa-viz](https://drive.google.com/uc?export=view&id=1IxI9Aga4ziLuuvSlUOKYnXcbItoUiIf2)


â€¢ [Requirements](#requirements)  
â€¢ [Installation](#installation)  
â€¢ [Usage](#usage)  
â€¢ [Contributing](#contributing)  
â€¢Â [Acknowledgements](#acknowledgements)  

## Requirements
Please check the [requirements.txt](https://github.com/apugoneappu/vqa_visualise/blob/master/requirements.txt) file for the version numbers.

1. torchvision
2. seaborn
3. pandas
4. matplotlib
5. dotmap
6. streamlit
7. numpy
8. torch
9. torchvision
10. Pillow
11. PyYAML
12. opencv_python

## Installation
1. Install Anaconda 
2. Clone this repository and cd into it.  
```git clone https://github.com/apugoneappu/vqa_visualise.git && cd vqa_visualise```
3. In a new environment (`new_env`)  
```pip install -r requirements.txt```  

## Usage
From the directory of this repository, do the following -

1. ```conda activate new_env```
2. ```streamlit run vqa_input.py```
3. In a browser tab, open the Network URL displayed in your terminal.

Done! ðŸŽ‰

## Contributing

First of all, thank you for wanting to contribute to this work! I will try and make your job as easy as possible.

## Acknowledgements 
This repository has been built by modifying the [OpenVQA repository](https://github.com/MILVLG/openvqa/). 

I would also like to thank [Yash Khandelwal](https://github.com/yash12khandelwal), [Nikhil Shah](https://github.com/itsshnik) and [Chinmay Singh](https://github.com/chinmay-singh) for their support and amazing suggestions!

